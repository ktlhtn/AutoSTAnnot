This project is the course work for a Tampere University course 'Signal Processing Innnovation Project' designed for students majoring in signal processing and machine learning. The course will be completed during spring of the year 2021. The students working on the project are Einari Vaaras, Mehmet Aydin and Kalle Lahtinen. The goal of the project (as described in the abstract) is to study the possibilities for automatically annotating spatial and temporal dimensions of sound objects detected in an audiostream with the help of a 360-degree video recording. The need for such a tool rises from the research of spatial audio in which data intensive modelling methods are heavily used. The goal of the project is to improve the quality of spatial audio data used in training of such models and to reduce manual labour related to the annotation of the data. The project will be implemented using open source tools. The main tool for development will be Python and available signal processing and machine learning libraries. The resulting application and its source code will be shared as open source for further research use.  