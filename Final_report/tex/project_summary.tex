\section{Project background}

The project aim was to research and develop a set of tools for automatically annotating spatial audio data with the use of visual detections made from 360-degree video recordings. 

\section{Project objectives, deliverables and planned timetable}

The overall goal of the project was to develop a proof-of-concept for providing spatiotemporal labels for audio events using a 360-degree camera and a microphone array. In addition to the course-specific deliverables such as the project plan report, the final report and the final presentation, the main deliverable of the project was agreed with the clients to be a GitHub repository containing the source codes that were created for the components of the project. Additionally, a thorough documentation of the source codes was agreed to be delivered on the GitHub repository. Practically the only timetable for the project was that some kind of functioning pipeline would be finished by the end of the course. On a weekly basis, the tasks for the next week were agreed on together with the clients on a Teams meeting.

\section{Project organization}

The project members were Einari Vaaras, Mehmet Aydin and Kalle Lahtinen. The open tasks related to the project were discussed on a daily basis in a project-specific Telegram channel. Before the project, there were no predefined roles for the project members, and the aim was to divide weekly tasks based on open discussion and equal contribution. During the project, each group member specialized in different categories of the project. Einari handled parts related to audio powermaps, beamforming, bounding box cleaning and mapping class labels. Mehmet specialized in experimenting with the recording devices such as providing test-scenes-to-be-experimented with on a weekly basis. Additionally, he studied about tracking methods and their implementations, especially Deep SORT \cite{deepsort}. Kalle took care of the video object detection pipeline, as well as defining a standardized CSV file output and producing audio event detections based on audio powermaps. In problematic situations such as code debugging, all group members participated in helping the group. In addition, course-related activities such as writing reports and planning presentations were carried out by all group members. Furthermore, all group members participated in the final recordings for the project, which are further discussed at the end of Section \ref{sec_implementation_steps}.


