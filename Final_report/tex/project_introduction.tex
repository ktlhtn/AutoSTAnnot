This project was the course work for a Tampere University course 'Signal Processing Innovation Project' designed for students majoring in signal processing and machine learning. The course was completed during the spring of the year 2021. The students working on the project were Einari Vaaras, Mehmet Aydin and Kalle Lahtinen. The goal of the project was to study the possibilities for automatically annotating spatial and temporal dimensions of sound objects detected in an audiostream with the help of a 360-degree video recording. The premise was that the objects are over two meters away from the the camera, so the project involves limited elevation angles. Another basic element was that including multiple sound sources is relevant, but there is no need to go to extremes, such as two similar objects being very close to each other.

The need for such a tool rises from the research of spatial audio in which data intensive modelling methods are heavily used. The goal of the project was to provide a proof-of-concept application which would improve the quality of spatial audio data used in the training of such models and reduce manual labour related to the annotation of the data. The project was implemented using open-source tools. The main tool for development was Python and available signal processing and machine learning libraries. In addition to Python, Matlab-scripts provided by the client were also used for the audio processing. The resulting application and its source code are shared as open-source (\url{https://github.com/ktlhtn/AutoSTAnnot}) for further research use under the Aladdin Free Public License.

The project proceeded according to the project plan made at the very beginning of the course. The end result of the project work was two different proof-of-concept processing pipelines that combine detections made from 360-video recordings with spatial audio recordings from the same scene. The pipeline outputs provide annotated spatio-temporal audio activity data that could be used for model training. The training data created with the pipelines were not yet tested in actual model training, but the findings from this project indicate that the basic method could be useful and the topic should be further researched.  